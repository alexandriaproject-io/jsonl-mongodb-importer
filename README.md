# jsonl-mongodb-importer
Imports jsonl datasets to mongodb with remapping

Each dataset is different so this project will contain a collection of scripts each for its own type of dataset. \
The datasets will be coverted to a strict data structure as follows: \
`NOTE: nothing is final and the structure may change as we encounter weireder datasets in the future`

### Dataset Source Card
```json
{
  "_id": "Mongo ObjectId",
  "datasetName": "String - Name of the dataset",
  "datasetUrl": "String - Dataset URL for reference",
  "datasetType": "String - Training data type: One of['llm-chat','llm-instruct','llm-completion', 'llm-analyze']",
  "datasetTargetLength": "String - Target context size: One of ['4k','8k','16k','32k','64k','128k']",
  "datasetOrigin": "String - Data origin: One of ['human','generated','mixed']"
}
```
**Dataset Type**
- llm-chat - Contains chat conversations between user and assistant
- llm-instruct - Contains user instruction and assistant response (can be multiple)
- llm-completion - Standard complete text type dataset
- llm-analyze - Dataset contains training data to allow the LLM to analyze the data and output a response ( book summary for example )

**Dataset Target Length** 
- The length is context approximation to avoid large context datasets to get mixed in with smaller ones

**Origin types:** 
- human - The dataset is fully created by humans
- generated - The dataset is fully generated by AI
- mixed - Some of the data is human made and some is AI

NOTE: datacard should be created manually in the DB ( the ID is required for the data items remapping )

### Dataset original jsonl row
Some datasets may require original reference, especially the multi message ones we will be splitting to their own lines
```json
{
  "_id": "Mongo ObjectId",
  "datasetId": "Mongo ObjectId@index - Id of the dataset card",
  "rawJsonString": "String - the original line of the jsonl",
  "rawJsonHash": "String - SHA256 of the original line to avoid duplicates"
}
```


### Dataset data row structure
We want the same format for all of the dataset items regardless of their original structure to make selecting or working with them easier
```json
{
   "_id": "Mongo ObjectId",
   "datasetId": "Mongo ObjectId@index - Id of the dataset card",
   "rawJsonId": "Mongo ObjectId@index@null - Id of the original data ( can be null )",
   "systemMessage": "String@empty - System message for the LLM",
   "contextMessages": [
     "Context message for training row",
     "Another context message for training row",
     ...
   ],
   "state": "String@default('new') - Data adjustments/completion may require special states",
   "seriesPosition": "Number - in multiple chat messages what is the positions", 
   "messages": [
     {
       "provider": "String - One of ['user','assistant','memory','segment']",
       "message": "String"
     },
     {
       "provider": "String - One of ['user','assistant','memory','segment']",
       "message": "String"
     },
     ...
   ]
}
```
**Provider types**
- user - Message was created by user
- assistant - Message was created by the LLM or assistant
- memory - Message was taken from a vector DB
- segment - The default option for texts or analyze type llm training sets

## Virtual environment activation

windows:
```
.\env\Scripts\activate
```

Linux
```
source env/bin/activate

```